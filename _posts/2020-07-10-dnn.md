---
title: An Introduction to Deep Neural Networks
tags: [Coding]
style: fill
color: light
description: A brief illustrative Introduction on how DNNs work.
---

The following blog article is based on my learnings from the FastAI lectures version 3 from 2019. I carefully summarized the lessons of Jeremy Howard.

### Introduction to a Neural Network

### Mathematical Foundations behind Neural Networks

Basically, neural networks (deep or shallow ones) are simple dot product multiplications consisting of weights (i.e. parameters) and activations. While weights store data and are used to do the calculations, activations are the results of the calculus.

In each layer of a neural network simple matrix multiplications are conducted. For example a (3,1) matrix multiplied with a (3,5) weight - matrix will result in a (5,1) matrix. The resulting matrix will then be run with an activation function. The _activated_ (5,1) matrix, then will be used to compute further matrix values.
Due to the laws of matrix multiplication the next matrix will be a (5, 8) matrix to result in a (8,1) matrix later. Depiction 1 visualizes this mathematical operation.

![Matrix Multiplication Example](https://i.imgur.com/QsP308l.png)

### Why do Neural Networks work?

The theorem called the '[Universal Approximation](https://en.wikipedia.org/wiki/Universal_approximation_theorem)' makes deep neural networks work. The theorem states:
'In the mathematical theory of artificial neural networks, universal approximation theorem type results state that a feed-forward network constructed of artificial neurons can approximate arbitrary well real-valued continuous functions on compact subsets of R.'

This means that if you have stacks of linear functions and non-linearities, then your model can approximate any function arbitrarily closely. Given the millions of parameter that a deep neural network is usually processing there is enough flexibility to represent nature's complexities.

### Input Types and Preprocessing

Input Types | Preprocessing | Input
---|---|---
Text, Tabular, Images, Audio, Video | Tokenization, Numericalization, Principal Component Analysis, Matrix Factorization, Warping, Zooming, ... | From preprocessed Input take a random _mini-batch_ for Stochastic Gradient Descent.

Once, all data inputs are run through the neural net, you call that an epoch.

__Term Definitions:__

- Epoch: Complete run through all data points. Do not run it too often, else you may cause overfitting.
- Mini-batch: Random bunch of inputs used to update weights.
- Stochastic Gradient Descent: Gradient descent using random mini-batches.
- Tokenization: Representing a word/linguistic concept in tokens after text was converted.
- Numericalization: take all words, uniqueify & sort due to occurrence. Take maximal 60k words.
- Tabular data examples: fraud detection, sales forecasting, pricing, credit risk.
- Matrix factorization: number of factors is width of embedding matrix that are latent features.
- Principal Component Analysis: Linear transformation that extracts smaller number of features from input matrix.
- Image augmentation: Warping, zooming, rotating, padding, affine functions.
- Text augmentation: Over/undersampling, reversing text.

### Neural Net Architectures

The following image depicts a Neural Network Architecture, and displays concepts such as Transfer learning.

![Neural Network Architecture](https://i.imgur.com/k3xySU2.png)

__The presented terms are defined as:__

- Transfer learning: takes a model that works pretty well and trains last layers to fit your needs.
- Tensor: shape where every row & every column is of the same length, e.g. 4x3 matrix.
- Architecture: Math function to fit params to (e.g., y=x*a)
- Params/Coefficients: Numbers to update.
- Wikitext-103: Subset of most of articles from Wikipedia knowing language and the world.
- Discriminative Learning Rate: use different learning rates at different layers in the model.
- Recurrent Neural Network: recurrently going through layers and adding inputs (e.g. words)
- Generative Adverserial Network: Generate text or images by letting compete two different lauers in a model.
- U-Net: The left side starts with a big image and gradually makes it smaller until eventually you just have one prediction; U-Net takes all these and makes it bigger again & takes a copy across at every step of the downward path.

### Activation Functions

Are functions that, e.g., allow for classification of certain objects. The formular is presented hereafter:

Functions relating to the activation function are:

```
Activation(Layer+1) = activation function( W(Layer) * a(Layer) + b(Layer) )
Activation: softmax
With activation function: sigmoid
With W: weight
With a: activation
With b: bias

Backpropagation is calculating the reverse.
```

- Softmax: Function where all activations add up to 1 and are > 0.
- Bias: Numbers representing features (e.g. personal taste) & thus add flexibility & semantics (latent factors).
- Back propagation: Calculating Grads with respect to all matrices, and then updating by subtracting LR*grad.
- Activation Function: ReLU (rectified linear unit) is max(0, x) or sigmoid (-1, 1).

### Fitting and Regularization

The major goal of training deep neural networks is the avoidance of over- or underfitting. This can be optimized by initialization, and the use of stochastic gradient descent.

Terms:
- Overfitting pertains to fitting the data to closely, and not generalizing well on unseen data.
- Underfitting defines a too generic fitting approach which does not perform well even on training data.
- Gradient Descent: Algorithm that minimizes functions. It starts with an initial sets of parameters and iteratively moves towards a set of params that minimizes the function.
- Regularization: Takes parameters & penalizes complexity but squares them to only have positives.


### The Learning Process: Stochastic Gradient Descent

![Learning Rate](https://i.imgur.com/NWbraDx.png)

__Related Terms:__
- Learning rate: the LR states how quickly params are updated in a model.
- Loss function: telling how far/close your training data is to the correct answer by compounding parameters & activations.
  - Mean Squared Error (MSE): is the loss function (Å·-y)^2.mean(), i.e. how far  is the line from all data points in plot.
  - Cross Entropy Loss: negative log-likelihood loss that penalizes incorrect confident & correct unconfident predictions.
- Superconvergence: One cycle uses low learning rate & high momentum and thre other way round.
- Weight Decay: Subtracts some constant and weights everytime a batch is processed.
- Momentum: Update of step is based on x of derivative and 1-x of previous direction.
- RMS Prop: uses exponentially weighted moving average (EWMA) w/ gradient squared (if grad is small).
- Adam: uses RMS Prop & Momentum divided by EWMA and takes .9 step in previous steps direction.
- Dropout: Taking out a number of activations.
